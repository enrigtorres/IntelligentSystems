library(tidyverse) #data manipilation
library(GGally) # nice scatterplot matrix
library(FactoMineR) # PCA computation
install.packages(c("GGally", "FactoMineR", "factoextra", "missMDA", "gridExtra"))
library(GGally)
library(FactoMineR)
library(factoextra)
library(missMDA)
library(gridExtra)
library(tidyverse) #data manipilation
library(GGally) # nice scatterplot matrix
library(FactoMineR) # PCA computation
library(factoextra) # nice plotting for PCA objects
library(missMDA) # to determine number of PC's through crossvalidation
library(gridExtra) # to build grid of plots
#check you have the correct data set
cereals <- read.table("cerealdata.txt", header=TRUE, as.is=TRUE, na.strings="-1")
#check you have the correct data set
cereals <- read.table("cerealdata.txt", header=TRUE, as.is=TRUE, na.strings="-1")
#check you have the correct data set
cereals <- read.table("cerealdata.txt", header=TRUE, as.is=TRUE, na.strings="-1")
#check you have the correct data set
cereals <- read.table("/Desktop/cerealdata.txt", header=TRUE, as.is=TRUE, na.strings="-1")
#check you have the correct data set
cereals <- read.table("../Desktop/cerealdata.txt", header=TRUE, as.is=TRUE, na.strings="-1")
#check you have the correct data set
cereals <- read.table("users/enrigtorres/Desktop/cerealdata.txt", header=TRUE, as.is=TRUE, na.strings="-1")
pp <- read.csv("paris_paintings.csv",
na.strings = c("NA","n/a", "", "#NAME?", " ", "Unknown", "X"),
stringsAsFactors = FALSE)
pp <- read.csv("paris_paintings.csv",
na.strings = c("NA","n/a", "", "#NAME?", " ", "Unknown", "X"),
stringsAsFactors = FALSE)
pp <- read.csv("paris_paintings.csv",
na.strings = c("NA","n/a", "", "#NAME?", " ", "Unknown", "X"),
stringsAsFactors = FALSE)
dim(pp)
# data cereals, import, change column names, remove NA's, define shelf as a factor
cereals <- read.table("cereal.txt", header=FALSE, as.is=TRUE, na.strings="-1")
pp <- read.csv("/Users/enrigtorres/Desktop/Universidad/Master/First semester/Statistical Data Analysis/First exam/Labs/paris_paintings.csv",
na.strings = c("NA","n/a", "", "#NAME?", " ", "Unknown", "X"),
stringsAsFactors = FALSE)
dim(pp)
str(pp)
pp$price<- as.numeric(gsub(",","",pp$price))
?gsub
# Some useful commands
head(pp)
table(pp$year)
summary(pp$price)
# Compare de distribution of price and log(price). What do you observe?
hist(pp$price)
hist(log(pp$price))
boxplot(log(pp$price) ~pp$school_pntg)
boxplot(log(pp$price) ~pp$year)
boxplot(pp$price ~pp$school_pntg)
boxplot(log(pp$price) ~pp$school_pntg)
boxplot(log(pp$price) ~pp$Shape_nn)
##
sum(complete.cases(pp))
# Summarize (count) NA's per variable
t=pp%>%summarise_all(funs(sum(is.na(.))))
library(magrittr)
# Summarize (count) NA's per variable
t=pp%>%summarise_all(funs(sum(is.na(.))))
library(dplyr)
# Summarize (count) NA's per variable
t=pp%>%summarise_all(funs(sum(is.na(.))))
t
# Visualizing missing data
library("Amelia")
missmap(pp)
# Recoding shape of paintings
table(pp$Shape)
pp %>%
group_by(Shape) %>%
summarise(n = n()) %>%
arrange(n)
# recode in variable Shape_n
pp=pp %>%
mutate(
Shape_n = fct_recode(
Shape,
octagon="octogon",
oval="ovale",
round="ronde",
rect="squ_rect",
NULL="")
)
library(forcats)
# recode in variable Shape_n
pp=pp %>%
mutate(
Shape_n = fct_recode(
Shape,
octagon="octogon",
oval="ovale",
round="ronde",
rect="squ_rect",
NULL="")
)
# Lumping shape of paintings (1) in variable Shape_nn
pp=pp %>%
mutate(
Shape_nn = fct_lump(
Shape)
)
head(pp)
# Is the mean price different through the different categories of these variables?
# One way anova
table(pp$mat_n)
table(pp$year)
table(pp$school_pntg)
table(pp$dealer)
table(pp$diff_origin)
table(pp$endbuyer)
# distribution of log(price) through one categorical variable
ggplot(data = pp, aes(y=price, x=materialCat, col=materialCat)) +
geom_boxplot() +
scale_y_continuous(breaks=c(10,1000,3000),trans = scales::log_trans(base=exp(1)))
library(ggplot2)
# distribution of log(price) through one categorical variable
ggplot(data = pp, aes(y=price, x=materialCat, col=materialCat)) +
geom_boxplot() +
scale_y_continuous(breaks=c(10,1000,3000),trans = scales::log_trans(base=exp(1)))
# distribution of log(price) through two categorical variables, three different ways to
# do the same plot.
# They can be complemented with interaction plots
ggplot(data = pp, aes(y=logprice, x=materialCat, col=factor(prevcoll))) +
geom_boxplot()
ggplot(data = pp, aes(y=price, x=materialCat, col=factor(prevcoll))) +
geom_boxplot() +
scale_y_log10()
ggplot(data = pp, aes(y=price, x=materialCat, col=factor(prevcoll))) +
geom_boxplot() +
scale_y_continuous(breaks=c(10,1000,3000),trans = scales::log_trans(base=exp(1)))
interaction.plot(pp$materialCat, pp$prevcoll, pp$logprice, fun=median,col=c("red","green"),pch=c(15,19), type="b", trace.label="previousow")
# Quantitative var =logprice, categorical variables: diff_origin, endbuyer
table(pp$endbuyer,pp$diff_origin)
ggplot(data = pp, aes(y=price, x=endbuyer, col=factor(diff_origin))) +
geom_boxplot() +
scale_y_continuous(breaks=c(10,1000,3000),trans = scales::log_trans(base=exp(1)))
# interaction plot: fun=mean, median.
# The effect of diff_origin is consistent through all 5 endbuyers. This suggests
# that there is not an interaction effect.
interaction.plot(pp$endbuyer, pp$diff_origin, pp$logprice, fun=median,col=c("red","green"),pch=c(15,19), type="b", trace.label="DiffOrigin")
# You can try an interaction plot with dealer and diff_origin
interaction.plot(pp$dealer, pp$diff_origin, pp$logprice, fun=median,col=c("red","green"),pch=c(15,19), type="b", trace.label="DiffOrigin")
ggplot(data = pp, aes(y=price, x=dealer, col=factor(diff_origin))) +
geom_boxplot() +
scale_y_continuous(breaks=c(10,1000,3000),trans = scales::log_trans(base=exp(1)))
# How does the price distribution change over the years?
# compare these plots
ggplot(pp,aes(x=price, y=as.factor(year)))+
geom_density_ridges(scale=0.9)
ggplot(data = pp, aes(x=logprice, y=as.factor(year))) +
geom_density_ridges(scale=0.9)
install.packages("ggridges")
library(ggridges)
# How does the price distribution change over the years?
# compare these plots
ggplot(pp,aes(x=price, y=as.factor(year)))+
geom_density_ridges(scale=0.9)
ggplot(pp,aes(x=logprice, y=as.factor(year), fill=factor(..quantile..)))+
stat_density_ridges(geom = "density_ridges_gradient", calc_ecdf = TRUE, quantiles = 4, quantile_lines = TRUE, scale=0.9)
ggplot(pp, aes(x=logprice, y=as.factor(year))) +
geom_density_ridges(jittered_points = TRUE,
position = position_points_jitter(width = 0.05, height = 0),
point_shape = '|', point_size = 1, alpha = 0.7, scale=0.7)
# Let's explore the relationship between logprice and Surface
# (of painting in square inches)
summary(pp$Surface)
which(pp$Surface==0)
ind=which(pp$Surface==0)
pp[ind,]
pp_surf=pp[-ind,]
pp_surf=as.data.frame(pp_surf)
# Let's try lo linearize the relationship between both variables
plot(pp_surf$Surface~pp_surf$logprice)
pp_surf$logsurf=log(pp_surf$Surface)
plot(pp_surf$logsurf,pp_surf$logprice)
# Linear correlations by year between logprice and logsurface
pp_surf %>%
group_by(year) %>%
summarise(n(), min(price), max(price))
corr_year=pp_surf %>%
group_by(year) %>%
do(as.data.frame(cor(cbind(.$logprice,.$logsurf),use="complete.obs")))
corr_year=pp_surf %>%
group_by(year) %>%
do(as.data.frame(cor(cbind(.$logprice,.$logsurf),use="complete.obs")[2,1]))
colnames(corr_year)=c("year","correlation")
corr_year=as.data.frame(corr_year)
ggplot(data = corr_year, aes(x = year, y = correlation))+
geom_line(color = "#00AFBB", size = 1)+scale_x_discrete(limits=c(1764:1780))
# Material and price (for finished paintings and for unfinished paintings).
ggplot(pp_surf, aes(x=Surface,y=logprice, color=factor(materialCat)))+geom_point()+geom_smooth(method="lm")
ggplot(pp_surf[pp_surf$finished=="1",], aes(x=logsurf,y=logprice, color=factor(materialCat)))+geom_point()+geom_smooth(method="lm")
ggplot(pp_surf[pp_surf$finished=="0",], aes(x=logsurf,y=logprice, color=factor(materialCat)))+geom_point()+geom_smooth(method="lm")
# Shape and price.
ggplot(pp_surf, aes(x=logsurf,y=logprice, color=factor(Shape_nn)))+geom_point()+geom_smooth(method="lm")
# Let's try to define a similiarity (or dissimilarity) index among schools of paintings
D=filter(pp,school_pntg=="D/FL" )
D=D[,c(16,34:60)]
SPA=filter(pp,school_pntg=="S" )
SPA=SPA[,c(16,34:60)]
FRA=filter(pp,school_pntg=="F" )
FRA=FRA[,c(16,34:60)]
IT=filter(pp,school_pntg=="I" )
IT=IT[,c(16,34:60)]
SPAIN=SPA %>% summarise_all(funs(median(.)))
DUTCH=D %>% summarise_all(funs(median(.)))
FRANCE=FRA %>% summarise_all(funs(median(.)))
ITALY=IT %>% summarise_all(funs(median(.)))
SPAIN=as.numeric(SPAIN)
DUTCH=as.numeric(DUTCH)
FRANCE=as.numeric(FRANCE)
ITALY=as.numeric(ITALY)
df=rbind(SPAIN,DUTCH,FRANCE,ITALY)
dist(df, method="binary")
1-dist(df, method="binary")
library(factoextra)
get_dist(df,method="binary")
fviz_dist(get_dist(df,method="binary")) #dissimilarity
fviz_dist(1-get_dist(df, method="binary")) #similarity
installed.packages("shiny")
installed.packages()
installed.packages("shiny")
install.packages("shiny")
library(shiny)
runExample("01_hello")
library(shiny)
# Define UI for app that draws a histogram ----
ui <- fluidPage(
# App title ----
titlePanel("Hello Shiny!"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Slider for the number of bins ----
sliderInput(inputId = "bins",
label = "Number of bins:",
min = 1,
max = 50,
value = 30)
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Histogram ----
plotOutput(outputId = "distPlot")
)
)
)
# Define server logic required to draw a histogram ----
server <- function(input, output) {
# Histogram of the Old Faithful Geyser Data ----
# with requested number of bins
# This expression that generates a histogram is wrapped in a call
# to renderPlot to indicate that:
#
# 1. It is "reactive" and therefore should be automatically
#    re-executed when inputs (input$bins) change
# 2. Its output type is a plot
output$distPlot <- renderPlot({
x    <- faithful$waiting
bins <- seq(min(x), max(x), length.out = input$bins + 1)
hist(x, breaks = bins, col = "#75AADB", border = "white",
xlab = "Waiting time to next eruption (in mins)",
main = "Histogram of waiting times")
})
}
shinyApp(ui = ui, server = server)
runApp("Desktop")
runApp("Desktop")
runApp("Shiny1")
runApp("/Users/enrigtorres/Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny1")
runApp("/Users/enrigtorres/Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny1")
runApp("/Users/enrigtorres/Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny1")
runApp("/Users/enrigtorres/Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny1", display.mode = "showcase")
runApp('Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny1')
runExample("02_text")
runExample("03_reactivity")
runExample("04_mpg")
runApp('Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny2')
runApp('Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny2')
runApp('Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny2')
runApp('Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny2')
runApp('Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny2')
runApp('Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny2')
runApp('Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny2')
runApp('Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny2')
runApp('Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny2')
runApp('Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny2')
runApp('Desktop/Universidad/Master/First semester/Data Visualization/Shiny/Shiny2')
library(tm)
library(ggplot2)
library(wordcloud)
library(RWeka)
library(reshape2)
source.pos = DirSource("/review_polarity/txt_sentoken/pos", encoding = "UTF-8")
source.pos = DirSource("review_polarity/txt_sentoken/pos", encoding = "UTF-8")
source.pos = DirSource("/Corpus/review_polarity/txt_sentoken/pos", encoding = "UTF-8")
c
source.pos = DirSource("../Corpus/review_polarity/txt_sentoken/pos", encoding = "UTF-8")
corpus = Corpus(source.pos)
source.pos = DirSource("/Users/enrigtorres/Desktop/Universidad/Master/FirstSemester/Intelligent Systems/NLP/Corpus/review_polarity/txt_sentoken/pos", encoding = "UTF-8")
corpus = Corpus(source.pos)
length(corpus)
summary(corpus[1:3])
inspect(corpus[1])
meta(corpus[[1]])
meta(corpus[[1]])$id
tdm
tdm = TermDocumentMatrix(corpus)
tdm
inspect(tdm[2000:2003,100:103])
length(dimnames(tdm)$Terms)
freq=rowSums(as.matrix(tdm))
head(freq,10)
plot(sort(freq, decreasing = T),col="blue",main="Word frequencies", xlab="Frequency-based rank", ylab = "Frequency")
tail(sort(freq),n=10)
sum(freq == 1)
---
title: "R Notebook"
output: html_notebook
---
clean
clean
clean()
library(rJava)
library(NLP)
library(openNLP)
install.packages("openNLP")
library(openNLP)
library(openNLP)
library(openNLPmodels.en)
library(tm)
library(stringr)
#check working directory
getwd()
setwd("~/Desktop/Universidad/Master/FirstSemester/Intelligent Systems/NLP/Assignment")
getSrcDirectory()
getSrcDirectory()[1]
current_path = rstudioapi::getActiveDocumentContext()$path
current_path
setwd(dirname(current_path ))
print( getwd() )
#load text
source = DirSource(current_path, encoding = "UTF-8")
#load text
source = DirSource("..", encoding = "UTF-8")
corpus = Corpus(source)
inspect(corpus[[1]])
#load text
source = DirSource("", encoding = "UTF-8")
current_path
#load text
source = DirSource("../", encoding = "UTF-8")
corpus = Corpus(source)
inspect(corpus[[1]])
data <- read.delim("allergy1.txt")
data <- read.delim(file.choose())
data <- readtext(file.choose())
install.packages("readtext")
library(readtext)
data <- readtext(file.choose())
data
data[1]
data.text
data[text]
#load text
source = DirSource("../corpus/", encoding = "UTF-8")
corpus = Corpus(source)
inspect(corpus[[1]])
#load text
source = DirSource("corpus/", encoding = "UTF-8")
corpus = Corpus(source)
inspect(corpus[[1]])
inspect(corpus[[2]])
inspect(corpus[[1]])
annotations = lapply(corpus, getAnnotationsFromDocument)
getAnnotationsFromDocument = function(doc){
x=as.String(doc)
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator <- Maxent_POS_Tag_Annotator()
y1 <- annotate(x, list(sent_token_annotator, word_token_annotator))
y2 <- annotate(x, pos_tag_annotator, y1)
return(y2)
}
annotations = lapply(corpus, getAnnotationsFromDocument)
head(annotations[[1]])
